{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "258299775ac8958e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T18:42:16.562726Z",
     "start_time": "2024-11-27T18:42:16.555956Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertTokenizer, BertModel\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291b44f1b03c9bdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T17:51:31.766227Z",
     "start_time": "2024-11-27T17:51:31.746657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using : NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Using : {torch.cuda.get_device_name(0)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb58d8576d3359c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T17:51:31.797482Z",
     "start_time": "2024-11-27T17:51:31.783232Z"
    }
   },
   "outputs": [],
   "source": [
    "file_path = 'final_questions.csv' \n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57e797ebeb60aad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T17:51:31.812619Z",
     "start_time": "2024-11-27T17:51:31.805364Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       Question Text     Chapter_name\n",
      "0                     1. Pascal, BASIC, and C are p.  Getting started\n",
      "1  2. A widget is to the blueprint for a widget a...  Getting started\n",
      "2       3. The two major components of an object are  Getting started\n",
      "3  4. In C++, a function contained within a class...  Getting started\n",
      "4  5. Protecting data from access by unauthorized...  Getting started\n",
      "The length of dataframe is :1532\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(f\"The length of dataframe is :{df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e35c9835450769",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T17:51:31.905518Z",
     "start_time": "2024-11-27T17:51:31.886405Z"
    }
   },
   "outputs": [],
   "source": [
    "questions = df['Question Text'].tolist()\n",
    "labels = df['Chapter_name'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec0ccc7ee0cea7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T17:51:32.724536Z",
     "start_time": "2024-11-27T17:51:31.914023Z"
    }
   },
   "outputs": [],
   "source": [
    "label_map = {label: idx for idx, label in enumerate(set(labels))}\n",
    "map_to_label ={idx:label for idx, label in enumerate(set(labels))}\n",
    "labels = [label_map[label] for label in labels]\n",
    "num_classes = len(label_map)\n",
    "# Load BERT tokenizer and define constants\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2857950b9f46c07d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T17:51:32.756178Z",
     "start_time": "2024-11-27T17:51:32.736262Z"
    }
   },
   "outputs": [],
   "source": [
    "#Super Parameters\n",
    "max_length = 64\n",
    "batch_size = 8\n",
    "learning_rate = 4e-5 # (1e-5 =55%) (3e-5 = 65%) (8e-5=67%)\n",
    "num_epochs = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0074568335dd3e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T17:51:32.772182Z",
     "start_time": "2024-11-27T17:51:32.767178Z"
    }
   },
   "outputs": [],
   "source": [
    "#Intializing a question_dataset \n",
    "class QuestionDataset(Dataset):\n",
    "    def __init__(self, questions, labels, tokenizer, max_length):\n",
    "        self.questions = questions\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        question = self.questions[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = (self.tokenizer.encode_plus(\n",
    "            question,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        ))\n",
    "        \n",
    "        input_ids = encoding['input_ids'].squeeze()\n",
    "        attention_mask = encoding['attention_mask'].squeeze()\n",
    "        \n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d4ce7057922eca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T17:51:32.787607Z",
     "start_time": "2024-11-27T17:51:32.782608Z"
    }
   },
   "outputs": [],
   "source": [
    "# BERTClassifier  bert model to connected to a linear neural network to predict class\n",
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self, bert_model_name, num_classes):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_output = outputs.pooler_output\n",
    "        return self.fc(cls_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223cf771c9c3e9d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T17:51:37.586121Z",
     "start_time": "2024-11-27T17:51:32.803190Z"
    }
   },
   "outputs": [],
   "source": [
    "model = BERTClassifier('bert-base-uncased', num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebee481d891caa67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T17:51:37.601488Z",
     "start_time": "2024-11-27T17:51:37.593146Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86463735c8144d66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T17:51:37.616596Z",
     "start_time": "2024-11-27T17:51:37.609848Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = QuestionDataset(questions, labels, tokenizer, max_length)\n",
    "train_size = int(0.8* len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec460304d5867e31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T17:51:37.647658Z",
     "start_time": "2024-11-27T17:51:37.633444Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)# why we used adamW\n",
    "#why we used cross entropy loss\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9f6ed6a08f8466",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T17:51:37.663299Z",
     "start_time": "2024-11-27T17:51:37.652578Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae76487240d9446",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T17:56:06.408251Z",
     "start_time": "2024-11-27T17:51:37.671061Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/13, Training Loss: 3.0421944779235046\n",
      "Epoch 2/13, Training Loss: 2.4771701438086375\n",
      "Epoch 3/13, Training Loss: 1.8665876210509957\n",
      "Epoch 4/13, Training Loss: 1.3188200339481428\n",
      "Epoch 5/13, Training Loss: 0.8883377131098857\n",
      "Epoch 6/13, Training Loss: 0.5485400889165603\n",
      "Epoch 7/13, Training Loss: 0.301681107466484\n",
      "Epoch 8/13, Training Loss: 0.17110171494400733\n",
      "Epoch 9/13, Training Loss: 0.08511435294935069\n",
      "Epoch 10/13, Training Loss: 0.05680146831535287\n",
      "Epoch 11/13, Training Loss: 0.039455867590164985\n",
      "Epoch 12/13, Training Loss: 0.030546396287375842\n",
      "Epoch 13/13, Training Loss: 0.021492304879107645\n"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()#what is zero_grad\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {avg_train_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0b860fb68c5629",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T18:06:36.138439Z",
     "start_time": "2024-11-27T18:06:36.135110Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9ce22faf4bcc5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T18:42:31.094632Z",
     "start_time": "2024-11-27T18:42:21.080724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished playing sound for 10 seconds!\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread\n",
    "from playsound import playsound\n",
    "import time\n",
    "audio_file = 'alarm.mp3'\n",
    "def play_sound():\n",
    "    while True:\n",
    "        playsound(audio_file)\n",
    "sound_thread = Thread(target=play_sound, daemon=True)\n",
    "sound_thread.start()\n",
    "time.sleep(10)\n",
    "\n",
    "print(\"Finished playing sound for 10 seconds!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb161c1b9f134149",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T18:04:32.293914Z",
     "start_time": "2024-11-27T18:04:31.368823Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model, 'model_complete.pth') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d444269afb93ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T17:56:16.451622Z",
     "start_time": "2024-11-27T17:56:16.446616Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_question(question, model, tokenizer, device, max_length=32):\n",
    "    # Preprocess the question (tokenize)\n",
    "    encoding = tokenizer.encode_plus(\n",
    "        question,\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():  \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        _, predicted_class = torch.max(outputs, 1)\n",
    "\n",
    "    return predicted_class.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620c9d3024a2740c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T17:56:16.463187Z",
     "start_time": "2024-11-27T17:56:16.458288Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Generic Algorithms and STL': 0,\n",
       " 'Associative Containers': 1,\n",
       " 'Virtual Functions': 2,\n",
       " 'Templates': 3,\n",
       " 'Templates ': 4,\n",
       " 'Inheritance': 5,\n",
       " 'Copy Control': 6,\n",
       " 'Sequential Containers': 7,\n",
       " 'Multifile Programs': 8,\n",
       " 'Functions': 9,\n",
       " 'Objects and Classes': 10,\n",
       " 'Structures': 11,\n",
       " 'Loops and Decisions': 12,\n",
       " 'Pointers and Dynamic Memory': 13,\n",
       " 'String,Vectors, and Arrays': 14,\n",
       " 'Getting started': 15,\n",
       " 'Object-Oriented Programming': 16,\n",
       " 'Operator Overloading': 17,\n",
       " 'Expressions': 18,\n",
       " 'Statements': 19,\n",
       " 'Specialised Tools and Techniques': 20,\n",
       " 'C++ Programming Basics': 21,\n",
       " 'Streams and IO Library': 22,\n",
       " 'Tools for Large Programs': 23,\n",
       " 'Strings, Vectors, and Arrays': 24,\n",
       " 'Generic Algorithms': 25,\n",
       " 'Pointers': 26,\n",
       " 'Variable and Basic types': 27,\n",
       " 'Specialised Library Facilities': 28}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb9c92c76ea491c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T17:56:16.476331Z",
     "start_time": "2024-11-27T17:56:16.473215Z"
    }
   },
   "outputs": [],
   "source": [
    "question = \"How can you implement a template?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66075befd4a2ed0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T17:56:16.563176Z",
     "start_time": "2024-11-27T17:56:16.491386Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 3\n",
      "Templates\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predicted_class = predict_question(question, model, tokenizer, device)\n",
    "print(f\"Predicted class: {predicted_class}\")\n",
    "print(f'{map_to_label[predicted_class]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf3c87750b66356",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T17:56:16.575197Z",
     "start_time": "2024-11-27T17:56:16.570640Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(model, dataloader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_samples = 0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for batch in dataloader:\n",
    "            # Move inputs and labels to the device\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            # Get model predictions\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            _, predictions = torch.max(outputs, 1)  # Get the index of the highest logit\n",
    "            \n",
    "            # Count correct predictions\n",
    "            correct_predictions += (predictions == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d435cf345da2d53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T17:56:18.107195Z",
     "start_time": "2024-11-27T17:56:16.588215Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 65.47%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "val_accuracy = calculate_accuracy(model, val_loader, device)\n",
    "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5750935b6368fa5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T18:31:26.125104Z",
     "start_time": "2024-11-27T18:31:25.264859Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rathe\\AppData\\Local\\Temp\\ipykernel_23104\\4163326003.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  SModel =torch.load('model_complete.pth')\n"
     ]
    }
   ],
   "source": [
    "SModel =torch.load('model_complete.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9609cbce37d0a0d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T18:31:30.014895Z",
     "start_time": "2024-11-27T18:31:28.295108Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 65.47%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "val_accuracy = calculate_accuracy(model, val_loader, device)\n",
    "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cf940933de6e08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T17:56:18.175203Z",
     "start_time": "2024-11-27T17:56:18.172198Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
